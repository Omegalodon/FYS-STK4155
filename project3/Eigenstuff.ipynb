{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/josefhisanawi/miniforge3/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/josefhisanawi/miniforge3/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19151945 0.44928651 0.56059534 0.7790926  0.85655796 0.57086   ]\n",
      " [0.44928651 0.80187218 0.83542069 0.87928691 0.50459771 0.46858427]\n",
      " [0.56059534 0.83542069 0.37025075 0.46304108 0.45014287 0.40795805]\n",
      " [0.7790926  0.87928691 0.46304108 0.61539618 0.43205569 0.25629542]\n",
      " [0.85655796 0.50459771 0.45014287 0.43205569 0.31683612 0.63617981]\n",
      " [0.57086    0.46858427 0.40795805 0.25629542 0.63617981 0.70458131]]\n",
      "A =  Tensor(\"Const:0\", shape=(6, 6), dtype=float64)\n",
      "x0 =  Tensor(\"Const_1:0\", shape=(1, 6), dtype=float64)\n",
      "dnn_output =  Tensor(\"dnn/dense_1/BiasAdd:0\", shape=(1, 6), dtype=float64)\n",
      "x_trial =  Tensor(\"loss/transpose:0\", shape=(6, 1), dtype=float64)\n",
      "Tensor(\"loss/mul:0\", shape=(6, 6), dtype=float64)\n",
      "Tensor(\"loss/mul_1:0\", shape=(6, 6), dtype=float64)\n",
      "Tensor(\"loss/Tensordot_3/MatMul:0\", shape=(6, 1), dtype=float64)\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t5/qbpdx9511w3d833p3c9qvwrc0000gn/T/ipykernel_55509/316632233.py:47: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  current_layer = tf.layers.dense(previous_layer, num_hidden_neurons[l],activation=tf.nn.sigmoid)\n",
      "/var/folders/t5/qbpdx9511w3d833p3c9qvwrc0000gn/T/ipykernel_55509/316632233.py:50: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  dnn_output = tf.layers.dense(previous_layer, matrix_size)\n",
      "2022-12-19 20:56:44.255557: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 / 10000 loss:  1.4868191\n",
      "Step: 100 / 10000 loss:  0.016757816\n",
      "Step: 200 / 10000 loss:  0.0047608353\n",
      "Step: 300 / 10000 loss:  0.0017829945\n",
      "Step: 400 / 10000 loss:  0.00073457125\n",
      "Step: 500 / 10000 loss:  0.00031603556\n",
      "Step: 600 / 10000 loss:  0.00013915231\n",
      "Step: 700 / 10000 loss:  6.215657e-05\n",
      "Step: 800 / 10000 loss:  2.8055394e-05\n",
      "Step: 900 / 10000 loss:  1.2775068e-05\n",
      "Step: 1000 / 10000 loss:  5.865517e-06\n",
      "Step: 1100 / 10000 loss:  2.7157228e-06\n",
      "Step: 1200 / 10000 loss:  1.2684895e-06\n",
      "Step: 1300 / 10000 loss:  5.9803665e-07\n",
      "Step: 1400 / 10000 loss:  2.8475435e-07\n",
      "Step: 1500 / 10000 loss:  1.3699488e-07\n",
      "Step: 1600 / 10000 loss:  6.661951e-08\n",
      "Step: 1700 / 10000 loss:  3.2749906e-08\n",
      "Step: 1800 / 10000 loss:  1.6275052e-08\n",
      "Step: 1900 / 10000 loss:  8.174975e-09\n",
      "Step: 2000 / 10000 loss:  4.1481103e-09\n",
      "Step: 2100 / 10000 loss:  2.124234e-09\n",
      "Step: 2200 / 10000 loss:  1.0974879e-09\n",
      "Step: 2300 / 10000 loss:  5.715857e-10\n",
      "Step: 2400 / 10000 loss:  2.997767e-10\n",
      "Step: 2500 / 10000 loss:  1.5815997e-10\n",
      "Step: 2600 / 10000 loss:  8.4003436e-11\n",
      "Step: 2700 / 10000 loss:  4.4727742e-11\n",
      "Step: 2800 / 10000 loss:  2.3955615e-11\n",
      "Step: 2900 / 10000 loss:  1.28544215e-11\n",
      "Step: 3000 / 10000 loss:  6.8954105e-12\n",
      "Step: 3100 / 10000 loss:  3.732052e-12\n",
      "Step: 3200 / 10000 loss:  2.0299689e-12\n",
      "Step: 3300 / 10000 loss:  1.0881296e-12\n",
      "Step: 3400 / 10000 loss:  5.869749e-13\n",
      "Step: 3500 / 10000 loss:  3.2533237e-13\n",
      "Step: 3600 / 10000 loss:  1.7208457e-13\n",
      "Step: 3700 / 10000 loss:  9.177844e-14\n",
      "Step: 3800 / 10000 loss:  5.0256098e-14\n",
      "Step: 3900 / 10000 loss:  2.6460317e-14\n",
      "Step: 4000 / 10000 loss:  1.472896e-14\n",
      "Step: 4100 / 10000 loss:  7.06842e-15\n",
      "Step: 4200 / 10000 loss:  4.6259294e-15\n",
      "Step: 4300 / 10000 loss:  2.627528e-15\n",
      "Step: 4400 / 10000 loss:  1.2952602e-15\n",
      "Step: 4500 / 10000 loss:  8.51171e-16\n",
      "Step: 4600 / 10000 loss:  3.7007436e-16\n",
      "Step: 4700 / 10000 loss:  4.0708178e-16\n",
      "Step: 4800 / 10000 loss:  7.401487e-17\n",
      "Step: 4900 / 10000 loss:  7.401487e-17\n",
      "Step: 5000 / 10000 loss:  0.0\n",
      "Step: 5100 / 10000 loss:  0.0\n",
      "Step: 5200 / 10000 loss:  0.0\n",
      "Step: 5300 / 10000 loss:  0.0\n",
      "Step: 5400 / 10000 loss:  0.0\n",
      "Step: 5500 / 10000 loss:  0.0\n",
      "Step: 5600 / 10000 loss:  0.0\n",
      "Step: 5700 / 10000 loss:  0.0\n",
      "Step: 5800 / 10000 loss:  0.0\n",
      "Step: 5900 / 10000 loss:  0.0\n",
      "Step: 6000 / 10000 loss:  0.0\n",
      "Step: 6100 / 10000 loss:  0.0\n",
      "Step: 6200 / 10000 loss:  0.0\n",
      "Step: 6300 / 10000 loss:  0.0\n",
      "Step: 6400 / 10000 loss:  0.0\n",
      "Step: 6500 / 10000 loss:  0.0\n",
      "Step: 6600 / 10000 loss:  0.0\n",
      "Step: 6700 / 10000 loss:  0.0\n",
      "Step: 6800 / 10000 loss:  0.0\n",
      "Step: 6900 / 10000 loss:  0.0\n",
      "Step: 7000 / 10000 loss:  0.0\n",
      "Step: 7100 / 10000 loss:  0.0\n",
      "Step: 7200 / 10000 loss:  0.0\n",
      "Step: 7300 / 10000 loss:  0.0\n",
      "Step: 7400 / 10000 loss:  0.0\n",
      "Step: 7500 / 10000 loss:  0.0\n",
      "Step: 7600 / 10000 loss:  0.0\n",
      "Step: 7700 / 10000 loss:  0.0\n",
      "Step: 7800 / 10000 loss:  0.0\n",
      "Step: 7900 / 10000 loss:  0.0\n",
      "Step: 8000 / 10000 loss:  0.0\n",
      "Step: 8100 / 10000 loss:  0.0\n",
      "Step: 8200 / 10000 loss:  0.0\n",
      "Step: 8300 / 10000 loss:  0.0\n",
      "Step: 8400 / 10000 loss:  0.0\n",
      "Step: 8500 / 10000 loss:  0.0\n",
      "Step: 8600 / 10000 loss:  0.0\n",
      "Step: 8700 / 10000 loss:  0.0\n",
      "Step: 8800 / 10000 loss:  0.0\n",
      "Step: 8900 / 10000 loss:  0.0\n",
      "Step: 9000 / 10000 loss:  0.0\n",
      "Step: 9100 / 10000 loss:  0.0\n",
      "Step: 9200 / 10000 loss:  0.0\n",
      "Step: 9300 / 10000 loss:  0.0\n",
      "Step: 9400 / 10000 loss:  0.0\n",
      "Step: 9500 / 10000 loss:  0.0\n",
      "Step: 9600 / 10000 loss:  0.0\n",
      "Step: 9700 / 10000 loss:  0.0\n",
      "Step: 9800 / 10000 loss:  0.0\n",
      "Step: 9900 / 10000 loss:  0.0\n",
      "\n",
      "Eigenvector NN = \n",
      " [[0.40661034]\n",
      " [0.48043621]\n",
      " [0.38109344]\n",
      " [0.4249885 ]\n",
      " [0.38403461]\n",
      " [0.36127423]] \n",
      "\n",
      "Eigenvalue NN = \n",
      " [[3.37831241]] \n",
      " \n",
      "\n",
      "Eigenvector analytic = \n",
      " [[-0.40661035 -0.73608462  0.17401828  0.4431149  -0.20662339  0.15336576]\n",
      " [-0.48043619 -0.27441836 -0.4469813  -0.46474992  0.18274908 -0.49466518]\n",
      " [-0.38109342  0.22082369 -0.1473763  -0.38644582 -0.60274354  0.52119553]\n",
      " [-0.42498848  0.3696067  -0.41612106  0.49221703  0.43369944  0.28150689]\n",
      " [-0.38403463  0.44071847  0.34772163  0.27641179 -0.35722481 -0.57737445]\n",
      " [-0.36127426  0.05717523  0.673898   -0.34588329  0.49487878  0.21802093]]\n",
      "\n",
      "\n",
      "Eigenvalues analytic = \n",
      " [ 3.37831241 -0.7575536   0.62197516  0.18553643 -0.09221541 -0.335599  ]\n"
     ]
    }
   ],
   "source": [
    "# # Finding eigenvalues of matrices with neural networks. \n",
    "# Modified Script for finding the eigenvectors corresponding to the largest eigenvalue of a matrix with a neural network.\n",
    "# this is courtesy of Morthen who gave permission before use.\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph()\n",
    "# tf.set_random_seed(343)\n",
    "\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "#from lib import compute_dx_dt\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "matrix_size = 6\n",
    "\n",
    "A = np.random.random_sample(size=(matrix_size,matrix_size))\n",
    "#A = np.matrix('2 7 3 9 3 0;7 7 1 1 9 7;3 1 8 7 6 6;9 1 7 5 4 8;3 9 6 4 8 7;0 7 6 8 7 9', dtype=\"float64\")\n",
    "A = (A.T + A)/2.0\n",
    "start_matrix = A\n",
    "\n",
    "\n",
    "eigen_vals, eigen_vecs =  np.linalg.eig(A)\n",
    "print(A)\n",
    "A = tf.convert_to_tensor(A)\n",
    "print(\"A = \", A)\n",
    "\n",
    "x_0 = tf.convert_to_tensor(np.random.random_sample(size = (1,matrix_size)))\n",
    "print(\"x0 = \", x_0)\n",
    "\n",
    "## The construction phase\n",
    "\n",
    "num_iter = 10000\n",
    "num_hidden_neurons = [50]\n",
    "num_hidden_layers = np.size(num_hidden_neurons)\n",
    "\n",
    "\n",
    "with tf.variable_scope('dnn'):\n",
    "\n",
    "    previous_layer = x_0\n",
    "\n",
    "    for l in range(num_hidden_layers):\n",
    "        current_layer = tf.layers.dense(previous_layer, num_hidden_neurons[l],activation=tf.nn.sigmoid)\n",
    "        previous_layer = current_layer\n",
    "\n",
    "    dnn_output = tf.layers.dense(previous_layer, matrix_size)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    print(\"dnn_output = \", dnn_output)\n",
    "    \n",
    "    x_trial = tf.transpose(dnn_output)\n",
    "    print(\"x_trial = \", x_trial)\n",
    "    \n",
    "    temp1 = (tf.tensordot(tf.transpose(x_trial), x_trial, axes=1)*A)\n",
    "    temp2 = (1- tf.tensordot(tf.transpose(x_trial), tf.tensordot(A, x_trial, axes=1), axes=1))*np.eye(matrix_size)\n",
    "    func = tf.tensordot((temp1-temp2), x_trial, axes=1)\n",
    "    \n",
    "    print(temp1)\n",
    "    print(temp2)\n",
    "    print(func)\n",
    "    \n",
    "    func = tf.transpose(func)\n",
    "    x_trial = tf.transpose(x_trial)\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(func, x_trial)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    traning_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "g_dnn = None\n",
    "\n",
    "losses = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(num_iter):\n",
    "        sess.run(traning_op)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            l = loss.eval()\n",
    "            print(\"Step:\", i, \"/\",num_iter, \"loss: \", l)\n",
    "            losses.append(l)\n",
    "\n",
    "    x_dnn = x_trial.eval()\n",
    "x_dnn = x_dnn.T\n",
    "\n",
    "\n",
    "# ## Plotting loss over time\n",
    "\"\"\"\n",
    "plt.plot(losses[:5])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print()\n",
    "print(\"Eigenvector NN = \\n\", (x_dnn/(x_dnn**2).sum()**0.5), \"\\n\")\n",
    "# Finding eigevalues from eigenvec (largest)\n",
    "eigen_val_nn = x_dnn.T @ (start_matrix @ x_dnn) / (x_dnn.T @ x_dnn)\n",
    "\n",
    "print(\"Eigenvalue NN = \\n\", eigen_val_nn, \"\\n \\n\")\n",
    "print(\"Eigenvector analytic = \\n\", eigen_vecs)\n",
    "print(\"\\n\")\n",
    "print(\"Eigenvalues analytic = \\n\",eigen_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(6, 6), dtype=float64)\n",
      "(6, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(A)\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#  A = np.matrix('-8 -5  9  -3  8 10; -5 7 2 10 6 -9;9 2 -2 10 -9 -2; -3 10 10 -7 -9 -7 ;8 6 -9 -9 -10 -2;10 -9 -2 -7 -2 -5', dtype=\"float64\")\n",
    "\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40661035 -0.73608462  0.17401828  0.4431149  -0.20662339  0.15336576]\n",
      " [-0.48043619 -0.27441836 -0.4469813  -0.46474992  0.18274908 -0.49466518]\n",
      " [-0.38109342  0.22082369 -0.1473763  -0.38644582 -0.60274354  0.52119553]\n",
      " [-0.42498848  0.3696067  -0.41612106  0.49221703  0.43369944  0.28150689]\n",
      " [-0.38403463  0.44071847  0.34772163  0.27641179 -0.35722481 -0.57737445]\n",
      " [-0.36127426  0.05717523  0.673898   -0.34588329  0.49487878  0.21802093]]\n",
      "[[0.19151945 0.44928651 0.56059534 0.7790926  0.85655796 0.57086   ]\n",
      " [0.44928651 0.80187218 0.83542069 0.87928691 0.50459771 0.46858427]\n",
      " [0.56059534 0.83542069 0.37025075 0.46304108 0.45014287 0.40795805]\n",
      " [0.7790926  0.87928691 0.46304108 0.61539618 0.43205569 0.25629542]\n",
      " [0.85655796 0.50459771 0.45014287 0.43205569 0.31683612 0.63617981]\n",
      " [0.57086    0.46858427 0.40795805 0.25629542 0.63617981 0.70458131]]\n"
     ]
    }
   ],
   "source": [
    "print(eigen_vecs)\n",
    "print(start_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c18a61768fc7abaa090cb0e39a032a5e1845f6b549403c4737868c6cec32b910"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
